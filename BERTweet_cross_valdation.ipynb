{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xrjXpEiRoY-"
      },
      "source": [
        "# BERT models cross-validation pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmZ6V79eRr4K"
      },
      "source": [
        "### Library import and auxiliary function for cross-validation approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfduPYUYRcsd"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install -U sentence-transformers\n",
        "!pip install datasets\n",
        "#install nltk emoji library to be used with normalizeTweet()\n",
        "!pip install nltk emoji==0.6.0\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMWmiSIORcul"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import transformers\n",
        "from datasets import Dataset\n",
        "from datasets.table import Table\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "from datasets import Dataset , DatasetDict\n",
        "\n",
        "from evaluate import load\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold, ParameterGrid,  GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "\n",
        "metric = load('glue','sst2')\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "from TweetNormalize import normalizeTweet\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "import spacy\n",
        "import re\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "stopword_list = stopwords.words('english')\n",
        "\n",
        "doc_counter = 0\n",
        "def reset_counter():\n",
        "  global doc_counter\n",
        "  doc_counter = 0\n",
        "\n",
        "def increase_counter():\n",
        "  global doc_counter\n",
        "  doc_counter += 1\n",
        "  if doc_counter % 100 == 0:\n",
        "    print(doc_counter)\n",
        "\n",
        "def spacy_nlp_tokenizer(text):\n",
        "    increase_counter()\n",
        "\n",
        "    # substituting all space characters with a single space\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "\n",
        "    # we use spacy for main nlp tasks\n",
        "    doc = nlp(text)\n",
        "    # lemmatized tokens, skipping stopwords\n",
        "    lemmas = ['LEMMA_'+token.lemma_ for token in doc if not token.is_stop]\n",
        "    # entity_types\n",
        "    entity_types = ['NER_'+token.ent_type_ for token in doc if token.ent_type_]\n",
        "\n",
        "    # in case an entity linker is available, we can use it do put actual entities as\n",
        "    # features, e.g. Queen Elizabeth, Elizabeth II, Her Majesty -> KB2912\n",
        "    # see https://spacy.io/usage/training#entity-linker\n",
        "    # entities = ['ENT_'+token.ent_kb_id_ for token in doc if token.ent_kb_id_]\n",
        "\n",
        "    # we use a simple nltk function to create ngrams\n",
        "    lemma_bigrams = ['BI_'+p1+'_'+p2 for p1,p2 in nltk.ngrams(lemmas,2)]\n",
        "    lemma_trigrams = ['TRI_'+p1+'_'+p2+'_'+p3 for p1,p2,p3 in nltk.ngrams(lemmas,3)]\n",
        "\n",
        "    all_tokens = list()\n",
        "    all_tokens.extend(lemmas)\n",
        "    all_tokens.extend(lemma_bigrams)\n",
        "    all_tokens.extend(lemma_trigrams)\n",
        "    all_tokens.extend(entity_types)\n",
        "    return all_tokens\n",
        "\n",
        "from EDA_AUG import eda_4\n",
        "\n",
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print('Is GPU available for usage?', torch.cuda.is_available())\n",
        "print(\"How many devices available for 'cuda'?\", torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIimziM-Rcwg"
      },
      "outputs": [],
      "source": [
        "#import datasets\n",
        "df_en_train = pd.read_csv(\"/content/data_sets/corrected_df.csv\", sep=',', header=0)\n",
        "df_en_test = pd.read_csv(\"/content/data_sets/en_testing_labeled.tsv\", sep='\\t', header=0)\n",
        "\n",
        "df_en_train\n",
        "\n",
        "print(df_en_train.misogyny_category.value_counts())\n",
        "\n",
        "x_train_binary = [normalizeTweet(i) for i in df_en_train['text']]\n",
        "y_train_binary = [i for i in df_en_train['misogynous']]\n",
        "x_test_binary = [normalizeTweet(i) for i in df_en_test['text']]\n",
        "y_test_binary = [i for i in df_en_test['misogynous']]\n",
        "\n",
        "\n",
        "df_en_train.drop(df_en_train[df_en_train['misogyny_category'] == '0'].index, inplace = True)\n",
        "df_en_test.drop(df_en_test[df_en_test['misogyny_category'] == '0'].index, inplace = True)\n",
        "\n",
        "\n",
        "x_train_multi = [normalizeTweet(i) for i in df_en_train['text']]\n",
        "y_train_multi = [i for i in df_en_train['misogyny_category']]\n",
        "x_test_multi = [normalizeTweet(i) for i in df_en_test['text']]\n",
        "y_test_multi = [i for i in df_en_test['misogyny_category']]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJmV3a_8Rcyh"
      },
      "outputs": [],
      "source": [
        "#define a label encoding for multi_class categories\n",
        "ordered_labels = sorted(list(set(y_train_multi)))\n",
        "label_dict = {}\n",
        "k=0\n",
        "for i in ordered_labels:\n",
        "  label_dict[i] = k\n",
        "  k+=1\n",
        "\n",
        "label_dict\n",
        "\n",
        "y_train_multi = [label_dict[i] for i in df_en_train['misogyny_category']]\n",
        "y_test_multi = [label_dict[i] for i in df_en_test['misogyny_category']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNIWHUIESkHp"
      },
      "outputs": [],
      "source": [
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "8Ixtt1DuSknI",
        "outputId": "3d77e1bb-5c8c-4632-8c2f-d806942813cf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                Text  label\n",
              "0  Please tell me why the bitch next to me in the...      1\n",
              "1                 @USER @USER Bitch shut the fuck up      1\n",
              "2        @USER Dear cunt , please shut the fuck up .      1\n",
              "3              RT @USER : Pls shut the fuck up bitch      1\n",
              "4  RT @USER : \" when u gonna get your license \" S...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a43d3b8c-4350-4688-bb4b-f02bdfacb4d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Please tell me why the bitch next to me in the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@USER @USER Bitch shut the fuck up</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@USER Dear cunt , please shut the fuck up .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @USER : Pls shut the fuck up bitch</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @USER : \" when u gonna get your license \" S...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a43d3b8c-4350-4688-bb4b-f02bdfacb4d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a43d3b8c-4350-4688-bb4b-f02bdfacb4d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a43d3b8c-4350-4688-bb4b-f02bdfacb4d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                Text  label\n",
              "0  Please tell me why the bitch next to me in the...      2\n",
              "1                 @USER @USER Bitch shut the fuck up      2\n",
              "2        @USER Dear cunt , please shut the fuck up .      2\n",
              "3              RT @USER : Pls shut the fuck up bitch      2\n",
              "4  RT @USER : \" when u gonna get your license \" S...      2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4ecf51d-9869-45fc-8b71-7a6f5558e7a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Please tell me why the bitch next to me in the...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@USER @USER Bitch shut the fuck up</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@USER Dear cunt , please shut the fuck up .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @USER : Pls shut the fuck up bitch</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @USER : \" when u gonna get your license \" S...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4ecf51d-9869-45fc-8b71-7a6f5558e7a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4ecf51d-9869-45fc-8b71-7a6f5558e7a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4ecf51d-9869-45fc-8b71-7a6f5558e7a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#create dataframes from the normalized tweets\n",
        "\n",
        "df_train_binary = pd.DataFrame(data = {'Text': x_train_binary, 'label': y_train_binary},)\n",
        "df_test_binary = pd.DataFrame(data = {'Text': x_test_binary, 'label': y_test_binary},)\n",
        "df_train_multi = pd.DataFrame(data = {'Text': x_train_multi, 'label': y_train_multi},)\n",
        "df_test_multi = pd.DataFrame(data = {'Text': x_test_multi, 'label': y_test_multi},)\n",
        "\n",
        "display(df_train_binary.head())\n",
        "display(df_train_multi.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKAK_PZBSkpV"
      },
      "outputs": [],
      "source": [
        "#function used to perform BERTweet tokenization\n",
        "\n",
        "def support_tokenizer(df, tokenizer, max_length = 256):\n",
        "\n",
        "  input_ids = []\n",
        "  token_type_ids = []\n",
        "  attention_mask = []\n",
        "\n",
        "  for sentence in df['Text']:\n",
        "              #for each sentence, perform a tokenization compatible with bert models\n",
        "              #getting input_ids, token_type_ids and attention_mask\n",
        "              sent_tok = tokenizer.encode_plus(sentence, padding=\"max_length\", \\\n",
        "                                              truncation=True,\n",
        "                                              add_special_tokens=True,\n",
        "                                              max_length=256,\n",
        "                                              pad_to_max_length=True,\n",
        "                                              return_token_type_ids=True)\n",
        "\n",
        "\n",
        "              input_ids.append(sent_tok['input_ids'])\n",
        "              token_type_ids.append(sent_tok['token_type_ids'])\n",
        "              attention_mask.append(sent_tok['attention_mask'])\n",
        "\n",
        "\n",
        "  #crete a dataframe with the original information + the new tokenized data\n",
        "  tok_df = pd.DataFrame({'Text': df['Text'], 'label': df['label'],\n",
        "                         'input_ids': input_ids,'token_type_ids':token_type_ids,\n",
        "                         'attention_mask':attention_mask})\n",
        "  return tok_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mGDaN2tS8Xz"
      },
      "outputs": [],
      "source": [
        "#convert a pandas dataframe to a HuggingFace compatible one\n",
        "def convert_hg_dataset(df):\n",
        "  return Dataset(pa.Table.from_pandas(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofFuIJoqS8Zu"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizer, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "de653d05a9de453dbcf09d2352e714da",
            "a52896a83d3a46e9b9f4fd450dfe09c8",
            "35cce1ff012e4ac0902b4016263d7673",
            "05a77009909b46a6ace6a813e99d7a9f",
            "c59fbdeab1554d4e85978ffb98747374",
            "946debbb2ab74d8a906c08b28d01847e",
            "0b31119690c94c43854faaf70e18c3ee",
            "596553d3add84b26a590edd4f9393499",
            "2593e058154e4c9db8ff44bd96353cb1",
            "eb434865902047bc979eb04cca3033cf",
            "76f614930e9f47f5886fb1b0cf9984d2",
            "b4909b1f09a245e482963183e7b6ee34",
            "5c59865307124e49a1de4cd3959ba7da",
            "24582c23e3344c859c7624a35e825c5d",
            "ad00658bd79b4b87a1ecb159923b9f7b",
            "ad459c58223141558e4d4de75aad01a5",
            "b0b1da7d84194e7fb5a8b98bf2443a33",
            "7bd90c3fcd054284993304138f0596cc",
            "30bfb3ae9db848f992bc85fc20a4a9f4",
            "072fd9ae80e0439eb1fe0f661e1920e7",
            "6a5014a5d1d541c6b781444797217fe0",
            "eb71f4e92e6a4a7c8f20d3e29b7cc6de",
            "bb7e18a0a85a413398da01452ae50840",
            "6dfe8c0ffc194f2ca33f1169de9bde83",
            "55297ff5a88f4121858932d32b97b8bf",
            "e8cc5fcc29b344d5aea8d5b707b5b3ea",
            "238fe99e95b04f3fb6be19cf6c5903b6",
            "e5a11d17a68c4bf1b97ea5941b8af9e0",
            "34557ae391ab447a8cc10234242bcd7a",
            "aa33efce52704680a8c87c33a938e58e",
            "013e6ac763d846029f73a62e2e186f3c",
            "247a8f3d323b444daaaa41978b079090",
            "411594d08aec4b328e9ba5a9c644ae54"
          ]
        },
        "id": "jbEABocGS8bx",
        "outputId": "12b7c01f-fcae-4b68-8d85-264413a74b37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/558 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de653d05a9de453dbcf09d2352e714da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4909b1f09a245e482963183e7b6ee34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb7e18a0a85a413398da01452ae50840"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "#define two different tokenizers, one for roberta and the other for bertweet\n",
        "\n",
        "#roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)\n",
        "bertweet_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, truncation = True, do_lower_case = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfVVjf20S8e9"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, RobertaModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "3727a7efaa9543ffa5ed4f7d92395105",
            "1115a16c85054302b22915cd39514039",
            "8cd22898ca274529b86021a310640005",
            "9c7de4f19a1643908ed10922ef1de9f4",
            "b10c282ce29741d39ec4332a92c86fb0",
            "6b2be7d791d74b38888da85cd71b297c",
            "4b2fd718222549d09c9b1f0b590a82d8",
            "8feceeb50afa4990b1f523110c3d753b",
            "33f074ad45bc4837895979a4ea545d3d",
            "ff494a99501d4063a06af9b664b7bf43",
            "5d0cdabc9c504e878e9cb21900987cc6"
          ]
        },
        "id": "obhPyPFVSkrZ",
        "outputId": "af8126f9-f69c-47f9-ebf9-88f12f6db1cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/543M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3727a7efaa9543ffa5ed4f7d92395105"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#download pre-trained models\n",
        "\n",
        "#model_roberta = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\")\n",
        "model_bertweet = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUGI5H-ISktc"
      },
      "outputs": [],
      "source": [
        "#exploit sklearn libraries in order to have a classification report\n",
        "#these functions will be used combined with HugginFace training and testing transformers libraries\n",
        "\n",
        "def compute_metrics_binary(eval_pred):\n",
        "\n",
        "    predictions, labels = eval_pred\n",
        "    pred = np.argmax(predictions, axis=1)\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred )\n",
        "    recall = recall_score(y_true=labels, y_pred=pred, )\n",
        "    precision = precision_score(y_true=labels, y_pred=pred )\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    print(classification_report(labels, pred))\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "def compute_metrics_multi(eval_pred):\n",
        "\n",
        "    predictions, labels = eval_pred\n",
        "    pred = np.argmax(predictions, axis=1)\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred, average = None )\n",
        "    precision = precision_score(y_true=labels, y_pred=pred, average = None )\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred, average = None)\n",
        "\n",
        "    print(classification_report(labels, pred))\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAyfc3czSkwx"
      },
      "outputs": [],
      "source": [
        "#define a function that given a model_name from transformer library, performs a  k fold cross validation\n",
        "#for binary and multi class problems, given a parameters setting in input\n",
        "\n",
        "#the function always uses stratified cross validation for the classification problems\n",
        "\n",
        "def transformer_crossval(model_name, params, dataframe, tokenizer, k=5, problem = 'binary', random_state = 42):\n",
        "\n",
        "  if problem == 'binary':\n",
        "    compute_metrics = compute_metrics_binary\n",
        "  if problem == 'multi':\n",
        "    compute_metrics = compute_metrics_multi\n",
        "\n",
        "  skf = StratifiedKFold(n_splits=k, shuffle=True, random_state = random_state)\n",
        "  #definining a precise random state allows us to keep the same folds for different intantiations of the same function\n",
        "\n",
        "  X = dataframe['Text'] #consider the texts\n",
        "  y = dataframe['label'] #consider the labels\n",
        "\n",
        "  num_labels = len(set(y))\n",
        "\n",
        "  ordered_train_sets = []\n",
        "  ordered_validation_sets = []\n",
        "\n",
        "  tokenize_func = lambda sentences: tokenizer(sentences['Text'], \\\n",
        "                                            padding=\"max_length\", \\\n",
        "                                            truncation=True,\n",
        "                                            )\n",
        "\n",
        "  for train_index, test_index in skf.split(X, y):\n",
        "\n",
        "    #for each split done by skf.split(X, y), convert the pandas dataframe into a hg_dataset\n",
        "    #and perform tokenization on it.\n",
        "    #then save it in appropriate lists.\n",
        "\n",
        "    train_df = pd.DataFrame(data = {'Text': X.iloc[train_index, ], 'label': y.iloc[train_index]},)\n",
        "    validation_df = pd.DataFrame(data = {'Text': X.iloc[test_index, ], 'label': y.iloc[test_index]},)\n",
        "\n",
        "    train_df = support_tokenizer(train_df, tokenizer, max_length = 256)\n",
        "    validation_df = support_tokenizer(validation_df, tokenizer, max_length = 256)\n",
        "\n",
        "\n",
        "    train_df = convert_hg_dataset(train_df)\n",
        "    validation_df = convert_hg_dataset(validation_df)\n",
        "\n",
        "    ordered_train_sets.append(train_df)\n",
        "    ordered_validation_sets.append(validation_df)\n",
        "\n",
        "\n",
        "  loss_metrics_validation = []\n",
        "  accuracy_metrics_validation = []\n",
        "  f1_metrics_validation = []\n",
        "\n",
        "  for training_set, validation_set in zip(ordered_train_sets,ordered_validation_sets):\n",
        "    print(ordered_train_sets[0])\n",
        "    print(ordered_validation_sets[0])\n",
        "\n",
        "    #for each training and validation set, we perform a training and a validation\n",
        "    #with our model, saving the accuracy and validation score\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs= params['epoch'],             # total number of training epochs\n",
        "    per_device_train_batch_size= params['per_device_train_batch_size'],  # batch size per device during training\n",
        "    per_device_eval_batch_size= params['per_device_validation_batch_size'],   # batch size for evaluation\n",
        "    warmup_steps= params['warmup_steps'],                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay= params['weight_decay'],               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=20,\n",
        "    learning_rate = params['learning_rate']\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels= num_labels).to(device)\n",
        "\n",
        "    trainer = Trainer(\n",
        "    model= model,\n",
        "    args= training_args,\n",
        "    train_dataset=training_set,\n",
        "    eval_dataset=validation_set,\n",
        "    compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    evaluations = trainer.evaluate()\n",
        "\n",
        "    print(evaluations) #############################\n",
        "\n",
        "    loss_metrics_validation.append(evaluations['eval_loss'])\n",
        "\n",
        "    accuracy_metrics_validation.append(evaluations['eval_accuracy'])\n",
        "    f1_metrics_validation.append(evaluations['eval_f1'].mean())\n",
        "\n",
        "  result_dict = {\n",
        "  'avg_loss' : np.array(loss_metrics_validation).mean(),\n",
        "  'std_loss' : np.array(loss_metrics_validation).std(),\n",
        "  'avg_accuracy' : np.array(accuracy_metrics_validation).mean(),\n",
        "  'std_accuracy' : np.array(accuracy_metrics_validation).std(),\n",
        "  'avg_f1' : np.array(f1_metrics_validation).mean(),\n",
        "  'std_f1' : np.array(f1_metrics_validation).std(),\n",
        "  }\n",
        "\n",
        "  return result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOcn1M3-SphA"
      },
      "outputs": [],
      "source": [
        "#define a function which fit a transformer model to a dataframe and reports results given the test\n",
        "\n",
        "def transformer_fit_predict(model_name, params, dataframe_training, dataframe_test, tokenizer, problem = 'binary', random_state = 42):\n",
        "\n",
        "  if problem == 'binary':\n",
        "    compute_metrics = compute_metrics_binary\n",
        "  if problem == 'multi':\n",
        "    compute_metrics = compute_metrics_multi\n",
        "\n",
        "  y = dataframe_training['label'] #consider the labels\n",
        "\n",
        "  num_labels = len(set(y))\n",
        "\n",
        "  tokenize_func = lambda sentences: tokenizer(sentences['Text'], \\\n",
        "                                            padding=\"max_length\", \\\n",
        "                                            truncation=True,\n",
        "                                            )\n",
        "\n",
        "  train_df = support_tokenizer(dataframe_training, tokenizer, max_length = 256)\n",
        "  test_df = support_tokenizer(dataframe_test, tokenizer, max_length = 256)\n",
        "\n",
        "  train_df = convert_hg_dataset(train_df)\n",
        "  test_df = convert_hg_dataset(test_df)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs= params['epoch'],             # total number of training epochs\n",
        "    per_device_train_batch_size= params['per_device_train_batch_size'],  # batch size per device during training\n",
        "    per_device_eval_batch_size= params['per_device_validation_batch_size'],   # batch size for evaluation\n",
        "    warmup_steps= params['warmup_steps'],                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay= params['weight_decay'],               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=20,\n",
        "    learning_rate = params['learning_rate'])\n",
        "\n",
        "\n",
        "\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels= num_labels).to(device)\n",
        "\n",
        "  trainer = Trainer(\n",
        "    model= model,\n",
        "    args= training_args,\n",
        "    train_dataset=train_df,\n",
        "    eval_dataset=test_df,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "  trainer.train()\n",
        "\n",
        "  evaluations = trainer.evaluate()\n",
        "\n",
        "  print(evaluations)\n",
        "\n",
        "  return model, evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stratified cross-validation with BERTweet for binary class"
      ],
      "metadata": {
        "id": "uqpvljNCZ13B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMidycC3UUSF",
        "outputId": "1fabe103-3490-4b72-f243-59208cbab5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'learning_rate': 1e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.0001}\n",
            "{'epoch': 5, 'learning_rate': 1e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.01}\n",
            "{'epoch': 5, 'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.0001}\n",
            "{'epoch': 5, 'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.01}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'epoch': [5],\n",
        "              'per_device_train_batch_size' : [16],\n",
        "              'per_device_validation_batch_size' : [8,16],\n",
        "              'warmup_steps' : [500],\n",
        "              'learning_rate' : [1e-05,3e-5],\n",
        "              'weight_decay' : [0.0001, 0.01]\n",
        "              }\n",
        "\n",
        "\n",
        "grid = ParameterGrid(param_grid)\n",
        "\n",
        "updated_grid = []\n",
        "\n",
        "for i in grid:\n",
        "  if i['per_device_train_batch_size'] > i['per_device_validation_batch_size']:\n",
        "    updated_grid.append(i)\n",
        "\n",
        "\n",
        "#specify the different possible parameters configuration to test\n",
        "for x in updated_grid:\n",
        "  print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NOTE: outputs for the entire cross-validation procedure are not reported due to the difficulty of running it in a single colab session; best configuration for all cases is reported in the next cell every time transformer_crossval() is called"
      ],
      "metadata": {
        "id": "lJPtI2LgrtjS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAjV8fNeaBYL"
      },
      "outputs": [],
      "source": [
        "#test different configurations for the binary case\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in range(len(updated_grid)):\n",
        "\n",
        "  print('Testing with configuration: \\n')\n",
        "  print(updated_grid[i], end = '\\n\\n')\n",
        "\n",
        "  #tuple_result = (avg_loss, std_loss, avg_accuracy, std_accuracy,)\n",
        "  tuple_result = transformer_crossval(\"vinai/bertweet-base\" , updated_grid[i], df_train_binary, bertweet_tokenizer,k=5, problem = 'binary')\n",
        "  result = (updated_grid[i], tuple_result)\n",
        "  results.append(result)\n",
        "  print(tuple_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_config = {'weight_decay': 0.0001, 'warmup_steps': 500, 'per_device_validation_batch_size': 8, 'per_device_train_batch_size': 16, 'learning_rate': 3e-05, 'epoch': 5}\n"
      ],
      "metadata": {
        "id": "VL0aQkGIZ5qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_fit_predict(\"vinai/bertweet-base\" , best_config, df_train_binary, df_test_binary, bertweet_tokenizer, problem = 'binary')"
      ],
      "metadata": {
        "id": "61dnZkzqaK4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj5kZB2KWTKd"
      },
      "source": [
        "## Stratified cross-validation with BERTweet for multi-class\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rY9XlrxTUt5C"
      },
      "outputs": [],
      "source": [
        "#test different configurations and\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in range(len(updated_grid)):\n",
        "\n",
        "  print('Testing with configuration: \\n')\n",
        "  print(updated_grid[i], end = '\\n\\n')\n",
        "\n",
        "  #tuple_result = (avg_loss, std_loss, avg_accuracy, std_accuracy,)\n",
        "  tuple_result = transformer_crossval(\"vinai/bertweet-base\" , updated_grid[i], df_train_multi, bertweet_tokenizer,k=5, problem = 'multi')\n",
        "  result = (updated_grid[i], tuple_result)\n",
        "  results.append(result)\n",
        "  print(tuple_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDOnuHKHRHv9"
      },
      "outputs": [],
      "source": [
        "#crossvalidation results for multi-class case BERTweet [NO AUGMENTATION]\n",
        "{'epoch': 5, 'learning_rate': 1e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.0001}\n",
        "{'avg_loss': 0.9555049061775207, 'std_loss': 0.01990089166461212, 'avg_accuracy': 0.6688045572589427, 'std_accuracy': 0.020259804124640655, 'avg_f1': 0.41354925905999673, 'std_f1': 0.03231382637080065}\n",
        "\n",
        "{'epoch': 5, 'learning_rate': 1e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.01}\n",
        "{'avg_loss': 0.954667842388153, 'std_loss': 0.01865113807747386, 'avg_accuracy': 0.674584904079752, 'std_accuracy': 0.009966775463470062, 'avg_f1': 0.4224969606350145, 'std_f1': 0.02941109302009539}\n",
        "\n",
        "\n",
        "{'epoch': 5, 'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.0001}\n",
        "{'avg_loss': 0.949773371219635, 'std_loss': 0.03147020396051596, 'avg_accuracy': 0.682685766943118, 'std_accuracy': 0.015633047387544417, 'avg_f1': 0.5463946231350254, 'std_f1': 0.015116808746339593}\n",
        "\n",
        "\n",
        "{'epoch': 5, 'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.01}\n",
        "{'avg_loss': 0.9542999863624573, 'std_loss': 0.03613993268974634, 'avg_accuracy': 0.686747088883304, 'std_accuracy': 0.015550506742450145, 'avg_f1': 0.540460741372458, 'std_f1': 0.01830868482157618}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjbugEifWRVV"
      },
      "outputs": [],
      "source": [
        "#test result with the best parameter configuration\n",
        "\n",
        "best_configuration = {'epoch': 5, 'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.0001}\n",
        "\n",
        "transformer_fit_predict(\"vinai/bertweet-base\", best_configuration, df_train_multi, df_test_multi, bertweet_tokenizer, problem = 'multi')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuc32RRcX0I7"
      },
      "source": [
        "### Data augmentation approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGafl7EsWRcE"
      },
      "outputs": [],
      "source": [
        "#perform cross-validation with data-augmentation and see if it performs any better\n",
        "\n",
        "#the function extends the dataset given a certain label and a limit\n",
        "\n",
        "def enlarge_df(df, label, limit : float):\n",
        "  df_new = df\n",
        "  limit = int(len(df[df['label'] == label]['Text']) * limit)\n",
        "\n",
        "  to_add = []\n",
        "\n",
        "  for string in df[df['label'] == label]['Text']:\n",
        "    k = eda_4(sentence = string, alpha_sr = 0.2, alpha_ri = 0.0, alpha_rs=0.2, num_aug = 10) #generate 10 instances\n",
        "    for j in k:\n",
        "      if len(to_add) == limit:\n",
        "        print(len(to_add))\n",
        "        return df_new\n",
        "      df_new = df_new.append({'Text': j , 'label' : label}, ignore_index = True)\n",
        "      to_add.append(j)\n",
        "\n",
        "\n",
        "  return df_new\n",
        "\n",
        "\n",
        "df_train_multi_five = df_en_train\n",
        "df_test_multi_five = df_en_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIEpz7TcWYN1"
      },
      "outputs": [],
      "source": [
        "#rename multi-class dataset columns for consistency with enlarge_df\n",
        "\n",
        "df_train_multi_five = df_train_multi_five[['text','misogyny_category']].rename(columns={\"text\": \"Text\", \"misogyny_category\": \"label\"})\n",
        "df_test_multi_five = df_test_multi_five[['text','misogyny_category']].rename(columns={\"text\": \"Text\", \"misogyny_category\": \"label\"})\n",
        "\n",
        "for key, value in label_dict.items():\n",
        "  df_train_multi_five = df_train_multi_five.replace(key, value)\n",
        "  df_test_multi_five = df_test_multi_five.replace(key, value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5hDzan2cfqI",
        "outputId": "52072e24-b7da-4e02-ebb1-889f0bf1b5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n",
            "72\n",
            "167\n",
            "88\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    982\n",
              "3    501\n",
              "4    264\n",
              "2    217\n",
              "0    135\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#extend every label excpet discredit, the majority class\n",
        "\n",
        "for key, value in label_dict.items():\n",
        "    if key == 'discredit':\n",
        "        continue\n",
        "    new = enlarge_df(df_train_multi_five, value, 0.5)\n",
        "    df_train_multi_five = new\n",
        "\n",
        "df_train_multi_five['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c4kfGXf8WYR-"
      },
      "outputs": [],
      "source": [
        "#perform again a model selection\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in range(len(updated_grid)):\n",
        "\n",
        "  print('Testing with configuration: \\n')\n",
        "  print(updated_grid[i], end = '\\n\\n')\n",
        "\n",
        "  #tuple_result = (avg_loss, std_loss, avg_accuracy, std_accuracy,)\n",
        "  tuple_result = transformer_crossval(\"vinai/bertweet-base\" , updated_grid[i], df_train_multi_five, bertweet_tokenizer,k=5, problem = 'multi')\n",
        "  result = (updated_grid[i], tuple_result)\n",
        "  results.append(result)\n",
        "  print(tuple_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZV_LFSuWYUO"
      },
      "outputs": [],
      "source": [
        "#cross-validation results for BERTweet after EDA AUGMENTATION APPROACH\n",
        "\n",
        "\n",
        "{'epoch': 5, 'learning_rate': 1e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.0001}\n",
        "\n",
        "{'avg_loss': 0.836749529838562, 'std_loss': 0.02075077741974913, 'avg_accuracy': 0.7359447004608295, 'std_accuracy': 0.008935815405375743, 'avg_f1': 0.6608662137094996, 'std_f1': 0.017969838953794084}\n",
        "\n",
        "{'epoch': 5, 'learning_rate': 1e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.01}\n",
        "\n",
        "{'avg_loss': 0.8311222553253174, 'std_loss': 0.019607455106381306, 'avg_accuracy': 0.7345622119815667, 'std_accuracy': 0.009147204258654005, 'avg_f1': 0.6586178401516201, 'std_f1': 0.01348793240955729}\n",
        "\n",
        "{'epoch': 5, 'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.01}\n",
        "\n",
        "\n",
        "{'avg_loss': 0.8364081501960754, 'std_loss': 0.04591267743316787, 'avg_accuracy': 0.7497695852534563, 'std_accuracy': 0.017218010776285174, 'avg_f1': 0.7020609259300116, 'std_f1': 0.023128162178396007}\n",
        "\n",
        "\n",
        "\n",
        "{'epoch': 5, 'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.0001}\n",
        "\n",
        "\n",
        "\n",
        "{'avg_loss': 0.8197516322135925, 'std_loss': 0.051124447542434746, 'avg_accuracy': 0.7571428571428571, 'std_accuracy': 0.013870891191974566, 'avg_f1': 0.7080092538817573, 'std_f1': 0.0265260270643998}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GO9rg05WYWe"
      },
      "outputs": [],
      "source": [
        "#test result with the best parameter configuration\n",
        "\n",
        "best_configuration = {'epoch': 5, 'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.0001}\n",
        "\n",
        "transformer_fit_predict(\"vinai/bertweet-base\", best_configuration, df_train_multi_five, df_test_multi_five, bertweet_tokenizer, problem = 'multi')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ylve4sdWYZz"
      },
      "outputs": [],
      "source": [
        "#testing the augmented dataset with MLP\n",
        "\n",
        "parameters_mlp = {'hidden_layer_sizes': [(8,16,32),(16,32,64,128),(64,128,256),],\n",
        "                 'activation':['relu','logistic','tanh'],\n",
        "                 'solver': ['lbfgs','sgd','adam'],\n",
        "                 'max_iter' : [9000],\n",
        "                  'early_stopping' : [True]}\n",
        "\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "#find lingustic features relevant for classification\n",
        "\n",
        "def find_how_many(string_list,reference):\n",
        "  count = 0\n",
        "  for x in string_list:\n",
        "    if x == reference:\n",
        "      count += 1\n",
        "\n",
        "  return count\n",
        "\n",
        "def extract_adjs(string):\n",
        "  tweet_adjs= []\n",
        "  doc = nlp(string)\n",
        "  adjs = 0\n",
        "  for token in doc:\n",
        "    if token.pos_ == 'ADJ':\n",
        "     adjs += 1\n",
        "  return adjs\n",
        "\n",
        "def linguistic_extraction(dataset):\n",
        "  linguistic_features = []\n",
        "  for x in dataset:\n",
        "    lenght = len(x)\n",
        "    urls = find_how_many(x.split(),'HTTPURL')\n",
        "    users = find_how_many(x.split(),'@USER')\n",
        "    adjs =  extract_adjs(x)\n",
        "    linguistic_features.append([lenght] + [urls] + [users] + [adjs])\n",
        "  return linguistic_features\n",
        "\n",
        "def perform_gridsearch(classifier, param_grid, cv, X_train, y_train, X_test, y_test, scoring = None):\n",
        "\n",
        "  clf = GridSearchCV(estimator = classifier, param_grid = param_grid, n_jobs = -1, cv = cv, scoring = scoring)\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  best_model = clf.best_estimator_\n",
        "\n",
        "  predictions = best_model.predict(X_test)\n",
        "\n",
        "  print('Best configuration', clf.best_params_)\n",
        "  print('Best mean score for the validation', clf.best_score_)\n",
        "  print('Std for the best mean score across folds',clf.cv_results_['std_test_score'][clf.best_index_])\n",
        "  print('******************')\n",
        "  print('Classification report:')\n",
        "  print(classification_report(y_test, predictions, digits = 7))\n",
        "  print('Confusion matrix:')\n",
        "  cm = confusion_matrix(y_test, predictions)\n",
        "  print(cm)\n",
        "  print('******************')\n",
        "  print(clf.cv_results_['mean_test_score'])\n",
        "  return best_model\n",
        "\n",
        "skf = StratifiedKFold(shuffle=True, random_state = 42, n_splits = 5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h7Y3IWRCdhE"
      },
      "outputs": [],
      "source": [
        "x_train_multi = [normalizeTweet(i) for i in df_train_multi_five['Text']]\n",
        "y_train_multi = [i for i in df_train_multi_five['label']]\n",
        "x_test_multi = [normalizeTweet(i) for i in df_test_multi_five['Text']]\n",
        "y_test_multi = [i for i in df_test_multi_five['label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uwp3IBSCxUv"
      },
      "outputs": [],
      "source": [
        "linguistic_features_train_multi = linguistic_extraction(x_train_multi)\n",
        "linguistic_features_test_multi = linguistic_extraction(x_test_multi)\n",
        "\n",
        "vect = CountVectorizer(analyzer=spacy_nlp_tokenizer, min_df=5)\n",
        "reset_counter()\n",
        "\n",
        "X_train_tok_multi = vect.fit_transform(x_train_multi)\n",
        "reset_counter()\n",
        "\n",
        "X_test_tok_multi = vect.transform(x_test_multi)\n",
        "\n",
        "\n",
        "tfidf = TfidfTransformer()  # weighting\n",
        "tfidf.fit(X_train_tok_multi)\n",
        "X_train_vec_multi = tfidf.transform(X_train_tok_multi)\n",
        "X_test_vec_multi = tfidf.transform(X_test_tok_multi)\n",
        "\n",
        "\n",
        "X_train_vec_multi_arr = X_train_vec_multi.toarray()\n",
        "X_test_vec_multi_arr = X_test_vec_multi.toarray()\n",
        "\n",
        "X_train_full_multi = []\n",
        "X_test_full_multi = []\n",
        "\n",
        "\n",
        "\n",
        "embeddings_train_multi = model.encode(x_train_multi)\n",
        "embeddings_test_multi = model.encode(x_test_multi)\n",
        "\n",
        "for i in range(len(X_train_vec_multi_arr)):\n",
        "  arr1 = X_train_vec_multi_arr[i]\n",
        "  arr2 = embeddings_train_multi[i]\n",
        "  arr3 = linguistic_features_train_multi[i]\n",
        "  X_train_full_multi.append(np.concatenate((arr1,arr2,arr3), axis =0))\n",
        "\n",
        "for i in range(len(X_test_vec_multi_arr)):\n",
        "  arr1 = X_test_vec_multi_arr[i]\n",
        "  arr2 = embeddings_test_multi[i]\n",
        "  arr3 = linguistic_features_test_multi[i]\n",
        "  X_test_full_multi.append(np.concatenate((arr1,arr2,arr3), axis =0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqgdiUyXANZA",
        "outputId": "62502a71-dd7f-4790-b212-ac5f4e03c4b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best configuration {'activation': 'tanh', 'early_stopping': True, 'hidden_layer_sizes': (64, 128, 256), 'max_iter': 9000, 'solver': 'adam'}\n",
            "Best mean score for the validation 0.6607431437334649\n",
            "Std for the best mean score across folds 0.026382555174533463\n",
            "******************\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0  0.2142857 0.2727273 0.2400000        11\n",
            "           1  0.4363636 0.8510638 0.5769231       141\n",
            "           2  0.9333333 0.1129032 0.2014388       124\n",
            "           3  0.3039216 0.7045455 0.4246575        44\n",
            "           4  0.9629630 0.3714286 0.5360825       140\n",
            "\n",
            "    accuracy                      0.4782609       460\n",
            "   macro avg  0.5701734 0.4625337 0.3958204       460\n",
            "weighted avg  0.7126198 0.4782609 0.4406545       460\n",
            "\n",
            "Confusion matrix:\n",
            "[[  3   4   0   4   0]\n",
            " [  4 120   0  16   1]\n",
            " [  4  63  14  42   1]\n",
            " [  0  13   0  31   0]\n",
            " [  3  75   1   9  52]]\n",
            "******************\n",
            "[0.46080958 0.12901667 0.34981831 0.55917537 0.12847652 0.61776357\n",
            " 0.62884879 0.127491   0.65052596 0.43991541 0.127491   0.127491\n",
            " 0.127491   0.127491   0.127491   0.44436062 0.127491   0.127491\n",
            " 0.44934328 0.127491   0.63504001 0.47527502 0.127491   0.65061102\n",
            " 0.59056345 0.127491   0.66074314]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', early_stopping=True,\n",
              "              hidden_layer_sizes=(64, 128, 256), max_iter=9000)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#RESULTS WITH sparse matrix + embedding + linguistic features\n",
        "\n",
        "perform_gridsearch(MLPClassifier(), parameters_mlp, skf, X_train_full_multi, y_train_multi, X_test_full_multi, y_test_multi, scoring = 'f1_macro')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8dJjqpDHdZN"
      },
      "source": [
        "# From 5 labels to 3 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "OeE0MqfnANlo",
        "outputId": "e40e9d03-1519-4784-8437-8c1c36a73b14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Text  label\n",
              "0     Please tell me why the bitch next to me in the...      2\n",
              "1                    @USER @USER Bitch shut the fuck up      2\n",
              "2           @USER Dear cunt , please shut the fuck up .      2\n",
              "3                 RT @USER : Pls shut the fuck up bitch      2\n",
              "4     RT @USER : \" when u gonna get your license \" S...      2\n",
              "...                                                 ...    ...\n",
              "1722  @USER @USER @USER @USER This ugly bitch has a ...      1\n",
              "1723  @USER Your lady probably is a bitch though . M...      1\n",
              "1724  Women are bitches . 1 time , this bitch in BAL...      1\n",
              "1725  Any woman that likes me is a bitch . All women...      1\n",
              "1726  SINCE YOU'VE COMPLETELY PROVEN YOU'RE A COMPLE...      1\n",
              "\n",
              "[1727 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2157cc71-4f52-47f4-8899-bb7432b0a545\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Please tell me why the bitch next to me in the...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@USER @USER Bitch shut the fuck up</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@USER Dear cunt , please shut the fuck up .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @USER : Pls shut the fuck up bitch</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @USER : \" when u gonna get your license \" S...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1722</th>\n",
              "      <td>@USER @USER @USER @USER This ugly bitch has a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1723</th>\n",
              "      <td>@USER Your lady probably is a bitch though . M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1724</th>\n",
              "      <td>Women are bitches . 1 time , this bitch in BAL...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1725</th>\n",
              "      <td>Any woman that likes me is a bitch . All women...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1726</th>\n",
              "      <td>SINCE YOU'VE COMPLETELY PROVEN YOU'RE A COMPLE...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1727 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2157cc71-4f52-47f4-8899-bb7432b0a545')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2157cc71-4f52-47f4-8899-bb7432b0a545 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2157cc71-4f52-47f4-8899-bb7432b0a545');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df_train_multi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT1TAmpwHgTC"
      },
      "outputs": [],
      "source": [
        "#What happens dropping the most under-represented class and merging the other two ?\n",
        "\n",
        "df_train_multi_three = df_train_multi\n",
        "df_test_multi_three = df_test_multi\n",
        "\n",
        "df_train_multi_three = df_train_multi_three[df_train_multi_three.label != label_dict['derailing']]\n",
        "df_test_multi_three = df_test_multi_three[df_test_multi_three.label != label_dict['derailing']]\n",
        "\n",
        "df_train_multi_three.label.replace( [label_dict['dominance']],  [ label_dict['stereotype']]   ,  inplace=True)\n",
        "df_test_multi_three.label.replace( [label_dict['dominance']],  [ label_dict['stereotype']]   ,  inplace=True)\n",
        "\n",
        "df_train_multi_three = df_train_multi_three.reset_index()\n",
        "df_test_multi_three = df_test_multi_three.reset_index()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(df_train_multi_three['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5Gz5Qytcocl",
        "outputId": "70343620-7893-4cb0-d505-0c8e04194947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1, 3, 4}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict\n",
        "#0: discredit, 1: sexual_harassment, 2: stereotype_dominance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAeih5Fgcy4C",
        "outputId": "74f7f87c-6303-433b-df1d-28a190180df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'derailing': 0,\n",
              " 'discredit': 1,\n",
              " 'dominance': 2,\n",
              " 'sexual_harassment': 3,\n",
              " 'stereotype': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYAZaQhOHgV8"
      },
      "outputs": [],
      "source": [
        "df_train_multi_three['label'].replace([1,3,4], [0,1,2], inplace = True)\n",
        "df_test_multi_three['label'].replace([1,3,4], [0,1,2], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_multi_three['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj7Fdju1eCTP",
        "outputId": "83339f68-1c82-44c5-9193-dee757a79471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    982\n",
              "1    334\n",
              "2    321\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3KB9XbMHgZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a1140b-ad77-49bb-b97b-81a721ce1a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "167\n",
            "160\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1473\n",
              "1     501\n",
              "2     481\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "#extend every label excpet discredit, the majority class\n",
        "\n",
        "for key, value in label_dict.items():\n",
        "    if key == 0:\n",
        "        continue\n",
        "    new = enlarge_df(df_train_multi_three, value, 0.5)\n",
        "    df_train_multi_three = new\n",
        "\n",
        "df_train_multi_three['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ru9cUyoHgcb"
      },
      "outputs": [],
      "source": [
        "#perform again a model selection\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in range(len(updated_grid)):\n",
        "\n",
        "  print('Testing with configuration: \\n')\n",
        "  print(updated_grid[i], end = '\\n\\n')\n",
        "\n",
        "  #tuple_result = (avg_loss, std_loss, avg_accuracy, std_accuracy,)\n",
        "  tuple_result = transformer_crossval(\"vinai/bertweet-base\" , updated_grid[i], df_train_multi_three, bertweet_tokenizer,k=5, problem = 'multi')\n",
        "  result = (updated_grid[i], tuple_result)\n",
        "  results.append(result)\n",
        "  print(tuple_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ0EKtlRANoj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ebee1c5-ece0-440f-d3f2-64be258b81e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--bertweet-base/snapshots/118ab1d567653bec16bbb081eafb6f8942f72108/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"vinai/bertweet-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 130,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64001\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--bertweet-base/snapshots/118ab1d567653bec16bbb081eafb6f8942f72108/pytorch_model.bin\n",
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Text. If Text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 2455\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 770\n",
            "  Number of trainable parameters = 134902275\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='770' max='770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [770/770 09:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.092400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.067100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.960200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.956400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.901100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.870600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.826900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.691900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.677400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.677200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.567000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.490900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.495600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.422900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.406100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.447700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.489100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.427300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.530200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.499600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.367000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.343500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.300400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.369700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.309600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.235600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.369800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.304600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.234000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.186700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.216800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.229900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.158300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.191800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.076900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: Text. If Text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 449\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[0.59798995 0.57407407 0.91326531]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.84397163 0.70454545 0.6780303 ]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"[0.7        0.63265306 0.77826087]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.84      0.70       141\n",
            "           1       0.57      0.70      0.63        44\n",
            "           2       0.91      0.68      0.78       264\n",
            "\n",
            "    accuracy                           0.73       449\n",
            "   macro avg       0.70      0.74      0.70       449\n",
            "weighted avg       0.78      0.73      0.74       449\n",
            "\n",
            "{'eval_loss': 0.9769389629364014, 'eval_accuracy': 0.732739420935412, 'eval_precision': array([0.59798995, 0.57407407, 0.91326531]), 'eval_recall': array([0.84397163, 0.70454545, 0.6780303 ]), 'eval_f1': array([0.7       , 0.63265306, 0.77826087]), 'eval_runtime': 6.7204, 'eval_samples_per_second': 66.811, 'eval_steps_per_second': 8.482, 'epoch': 5.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(RobertaForSequenceClassification(\n",
              "   (roberta): RobertaModel(\n",
              "     (embeddings): RobertaEmbeddings(\n",
              "       (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
              "       (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
              "       (token_type_embeddings): Embedding(1, 768)\n",
              "       (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "       (dropout): Dropout(p=0.1, inplace=False)\n",
              "     )\n",
              "     (encoder): RobertaEncoder(\n",
              "       (layer): ModuleList(\n",
              "         (0): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (1): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (2): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (3): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (4): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (5): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (6): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (7): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (8): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (9): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (10): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "         (11): RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "       )\n",
              "     )\n",
              "   )\n",
              "   (classifier): RobertaClassificationHead(\n",
              "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "     (dropout): Dropout(p=0.1, inplace=False)\n",
              "     (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "   )\n",
              " ),\n",
              " {'eval_loss': 0.9769389629364014,\n",
              "  'eval_accuracy': 0.732739420935412,\n",
              "  'eval_precision': array([0.59798995, 0.57407407, 0.91326531]),\n",
              "  'eval_recall': array([0.84397163, 0.70454545, 0.6780303 ]),\n",
              "  'eval_f1': array([0.7       , 0.63265306, 0.77826087]),\n",
              "  'eval_runtime': 6.7204,\n",
              "  'eval_samples_per_second': 66.811,\n",
              "  'eval_steps_per_second': 8.482,\n",
              "  'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#test result with the best parameter configuration\n",
        "\n",
        "best_configuration = {'epoch': 5, 'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'per_device_validation_batch_size': 8, 'warmup_steps': 500, 'weight_decay': 0.0001}\n",
        "\n",
        "transformer_fit_predict(\"vinai/bertweet-base\", best_configuration, df_train_multi_three, df_test_multi_three, bertweet_tokenizer, problem = 'multi')\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de653d05a9de453dbcf09d2352e714da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a52896a83d3a46e9b9f4fd450dfe09c8",
              "IPY_MODEL_35cce1ff012e4ac0902b4016263d7673",
              "IPY_MODEL_05a77009909b46a6ace6a813e99d7a9f"
            ],
            "layout": "IPY_MODEL_c59fbdeab1554d4e85978ffb98747374"
          }
        },
        "a52896a83d3a46e9b9f4fd450dfe09c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_946debbb2ab74d8a906c08b28d01847e",
            "placeholder": "​",
            "style": "IPY_MODEL_0b31119690c94c43854faaf70e18c3ee",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "35cce1ff012e4ac0902b4016263d7673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_596553d3add84b26a590edd4f9393499",
            "max": 558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2593e058154e4c9db8ff44bd96353cb1",
            "value": 558
          }
        },
        "05a77009909b46a6ace6a813e99d7a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb434865902047bc979eb04cca3033cf",
            "placeholder": "​",
            "style": "IPY_MODEL_76f614930e9f47f5886fb1b0cf9984d2",
            "value": " 558/558 [00:00&lt;00:00, 19.3kB/s]"
          }
        },
        "c59fbdeab1554d4e85978ffb98747374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946debbb2ab74d8a906c08b28d01847e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b31119690c94c43854faaf70e18c3ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "596553d3add84b26a590edd4f9393499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2593e058154e4c9db8ff44bd96353cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb434865902047bc979eb04cca3033cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f614930e9f47f5886fb1b0cf9984d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4909b1f09a245e482963183e7b6ee34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c59865307124e49a1de4cd3959ba7da",
              "IPY_MODEL_24582c23e3344c859c7624a35e825c5d",
              "IPY_MODEL_ad00658bd79b4b87a1ecb159923b9f7b"
            ],
            "layout": "IPY_MODEL_ad459c58223141558e4d4de75aad01a5"
          }
        },
        "5c59865307124e49a1de4cd3959ba7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0b1da7d84194e7fb5a8b98bf2443a33",
            "placeholder": "​",
            "style": "IPY_MODEL_7bd90c3fcd054284993304138f0596cc",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "24582c23e3344c859c7624a35e825c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30bfb3ae9db848f992bc85fc20a4a9f4",
            "max": 843438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_072fd9ae80e0439eb1fe0f661e1920e7",
            "value": 843438
          }
        },
        "ad00658bd79b4b87a1ecb159923b9f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a5014a5d1d541c6b781444797217fe0",
            "placeholder": "​",
            "style": "IPY_MODEL_eb71f4e92e6a4a7c8f20d3e29b7cc6de",
            "value": " 843k/843k [00:00&lt;00:00, 5.19MB/s]"
          }
        },
        "ad459c58223141558e4d4de75aad01a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0b1da7d84194e7fb5a8b98bf2443a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd90c3fcd054284993304138f0596cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30bfb3ae9db848f992bc85fc20a4a9f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "072fd9ae80e0439eb1fe0f661e1920e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a5014a5d1d541c6b781444797217fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb71f4e92e6a4a7c8f20d3e29b7cc6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb7e18a0a85a413398da01452ae50840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6dfe8c0ffc194f2ca33f1169de9bde83",
              "IPY_MODEL_55297ff5a88f4121858932d32b97b8bf",
              "IPY_MODEL_e8cc5fcc29b344d5aea8d5b707b5b3ea"
            ],
            "layout": "IPY_MODEL_238fe99e95b04f3fb6be19cf6c5903b6"
          }
        },
        "6dfe8c0ffc194f2ca33f1169de9bde83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a11d17a68c4bf1b97ea5941b8af9e0",
            "placeholder": "​",
            "style": "IPY_MODEL_34557ae391ab447a8cc10234242bcd7a",
            "value": "Downloading (…)solve/main/bpe.codes: 100%"
          }
        },
        "55297ff5a88f4121858932d32b97b8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa33efce52704680a8c87c33a938e58e",
            "max": 1078931,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_013e6ac763d846029f73a62e2e186f3c",
            "value": 1078931
          }
        },
        "e8cc5fcc29b344d5aea8d5b707b5b3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_247a8f3d323b444daaaa41978b079090",
            "placeholder": "​",
            "style": "IPY_MODEL_411594d08aec4b328e9ba5a9c644ae54",
            "value": " 1.08M/1.08M [00:00&lt;00:00, 6.15MB/s]"
          }
        },
        "238fe99e95b04f3fb6be19cf6c5903b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a11d17a68c4bf1b97ea5941b8af9e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34557ae391ab447a8cc10234242bcd7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa33efce52704680a8c87c33a938e58e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "013e6ac763d846029f73a62e2e186f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "247a8f3d323b444daaaa41978b079090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "411594d08aec4b328e9ba5a9c644ae54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3727a7efaa9543ffa5ed4f7d92395105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1115a16c85054302b22915cd39514039",
              "IPY_MODEL_8cd22898ca274529b86021a310640005",
              "IPY_MODEL_9c7de4f19a1643908ed10922ef1de9f4"
            ],
            "layout": "IPY_MODEL_b10c282ce29741d39ec4332a92c86fb0"
          }
        },
        "1115a16c85054302b22915cd39514039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b2be7d791d74b38888da85cd71b297c",
            "placeholder": "​",
            "style": "IPY_MODEL_4b2fd718222549d09c9b1f0b590a82d8",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "8cd22898ca274529b86021a310640005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8feceeb50afa4990b1f523110c3d753b",
            "max": 542529064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33f074ad45bc4837895979a4ea545d3d",
            "value": 542529064
          }
        },
        "9c7de4f19a1643908ed10922ef1de9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff494a99501d4063a06af9b664b7bf43",
            "placeholder": "​",
            "style": "IPY_MODEL_5d0cdabc9c504e878e9cb21900987cc6",
            "value": " 543M/543M [00:07&lt;00:00, 79.3MB/s]"
          }
        },
        "b10c282ce29741d39ec4332a92c86fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b2be7d791d74b38888da85cd71b297c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2fd718222549d09c9b1f0b590a82d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8feceeb50afa4990b1f523110c3d753b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33f074ad45bc4837895979a4ea545d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff494a99501d4063a06af9b664b7bf43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d0cdabc9c504e878e9cb21900987cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}